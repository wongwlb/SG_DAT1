{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification\n",
    "\n",
    "Concepts in this Notebook:\n",
    "- Naive Bayes Classifiers\n",
    "- Train Test Split\n",
    "- Vectorizer (fit and transform)\n",
    "- Accuracy of training and test data\n",
    "- Sparse array vs normal array\n",
    "- Comparing classifiers in sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some extra resources:\n",
    "\n",
    "- [SKL Naive Bayes Documentation](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    "- [Stanford Naive Bayes Math](http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "critics = pd.read_csv('https://raw.githubusercontent.com/misrab/SG_DAT1/master/data/rt_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A winning animated feature that has something for everyone on the age spectrum.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics.quote[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb     publication                                              quote review_date  rtid      title\n",
       "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
       "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
       "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
       "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story\n",
       "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial vs Bernoulli Models\n",
    "\n",
    "- The **Multinomial model** actually counts occurences out of all possible occurences for probability - better for greater features\n",
    "- The **Bernoulli model** counts only all documents with presence of the word - better for fewer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the Count Vectorizer Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original texts: \n",
      "\tMath is great\n",
      "\tMath is really great\n",
      "\tExciting exciting Math\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "### How the Count Vectorizer Works - TODO\n",
    "#\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['Math is great', 'Math is really great', 'Exciting exciting Math']\n",
    "print \"Original texts: \\n\\t\", \"\\n\\t\".join(text)\n",
    "CountV = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# call 'fit' to build the vocabulary\n",
    "CountV.fit(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What is an ngram? - Follow along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'exciting',\n",
       " u'exciting exciting',\n",
       " u'exciting math',\n",
       " u'great',\n",
       " u'is',\n",
       " u'is great',\n",
       " u'is really',\n",
       " u'math',\n",
       " u'math is',\n",
       " u'really',\n",
       " u'really great']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountV.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 0)\t2\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "# Call 'transform' to convert text to a bag of words\n",
    "x = CountV.transform(text)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer uses a sparse array to save memory\n",
    "x_back = x.toarray()\n",
    "x_back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our Features (X) and Target (Y) for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a (nreview, nwords) array. Each row corresponds to a bag-of-words representation for a single review. This will be the input to the model.\n",
    "\n",
    "Y is a nreview-element 1/0 array, encoding whether a review is Fresh (1) or Rotten (0). This is the desired output\n",
    "\n",
    "Now you try and create X and Y - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 126031)\t1\n",
      "  (0, 70236)\t1\n",
      "  (0, 68218)\t1\n",
      "  (0, 30919)\t1\n",
      "  (0, 36918)\t1\n",
      "  (0, 6446)\t2\n",
      "  (0, 46504)\t1\n",
      "  (0, 136476)\t1\n",
      "  (0, 162696)\t1\n",
      "  (0, 32582)\t1\n",
      "  (0, 155773)\t1\n",
      "  (0, 74183)\t1\n",
      "  (0, 100464)\t1\n",
      "  (0, 108976)\t1\n",
      "  (0, 129252)\t1\n",
      "  (0, 124784)\t1\n",
      "  (0, 120073)\t1\n",
      "  (0, 130059)\t1\n",
      "  (0, 16454)\t1\n",
      "  (0, 43885)\t1\n",
      "  (0, 23678)\t1\n",
      "  (0, 75443)\t1\n",
      "  (0, 27068)\t1\n",
      "  (0, 126219)\t1\n",
      "  (0, 70242)\t1\n",
      "  :\t:\n",
      "  (14071, 145418)\t1\n",
      "  (14071, 110536)\t1\n",
      "  (14071, 39514)\t1\n",
      "  (14071, 44081)\t1\n",
      "  (14071, 146659)\t1\n",
      "  (14071, 141490)\t1\n",
      "  (14071, 74474)\t1\n",
      "  (14071, 7715)\t1\n",
      "  (14071, 37185)\t1\n",
      "  (14071, 39569)\t1\n",
      "  (14071, 61942)\t1\n",
      "  (14071, 98137)\t1\n",
      "  (14071, 1730)\t1\n",
      "  (14071, 59727)\t1\n",
      "  (14071, 70595)\t1\n",
      "  (14071, 131226)\t1\n",
      "  (14071, 70597)\t1\n",
      "  (14071, 44125)\t1\n",
      "  (14071, 59730)\t1\n",
      "  (14071, 145554)\t1\n",
      "  (14071, 131227)\t1\n",
      "  (14071, 1734)\t1\n",
      "  (14071, 110549)\t1\n",
      "  (14071, 37204)\t1\n",
      "  (14071, 71185)\t1\n"
     ]
    }
   ],
   "source": [
    "# Use SKLearn's train_test_split - TODO\n",
    "\n",
    "# Instantiate the vectorizer with n-grams of length one or two\n",
    "CountV = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# Create a Vector where each row is bag-of-words for a single quote\n",
    "X = CountV.fit_transform(critics.quote)\n",
    "print X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Create an array where each element encodes whether the array is Fresh or Rotten\n",
    "\n",
    "Y = (critics.fresh == 'fresh').values.astype(np.int)\n",
    "print Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use SKlearn's train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vector of all quotes\n",
    "rotten_CV = CountV.fit(critics.quote)\n",
    "\n",
    "# a few helper functions\n",
    "def accuracy_report(_clf):\n",
    "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
    "\n",
    "    #Print the accuracy on the test and training dataset\n",
    "    training_accuracy = _clf.score(xtrain, ytrain)\n",
    "    test_accuracy = _clf.score(xtest, ytest)\n",
    "\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    \n",
    "# a function to run some tests\n",
    "def AnalyzeReview(testquote, _clf):\n",
    "    print \"\\\"\"  + testquote + \"\\\" is judged by clasifier to be...\"\n",
    "    testquote = rotten_CV.transform([testquote])\n",
    "\n",
    "    if (_clf.predict(testquote)[0] == 1):\n",
    "        print \"... a fresh review.\"\n",
    "    else:\n",
    "        print \"... a rotten review.\"\n",
    "    return(_clf.predict(testquote)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Accuracy: 75.95%\n",
      "Accuracy on training data: 0.99\n"
     ]
    }
   ],
   "source": [
    "# TODO - run Multinomial NB, and report accuracy\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "print \"MultinomialNB\"\n",
    "clf_mn = MultinomialNB().fit(xtrain, ytrain)\n",
    "accuracy_report(clf_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB\n",
      "Accuracy: 65.89%\n",
      "Accuracy on training data: 0.87\n"
     ]
    }
   ],
   "source": [
    "# TODO - likewise for Bernoulli NB\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "print \"BernoulliNB\"\n",
    "clf_bern = BernoulliNB().fit(xtrain, ytrain)\n",
    "accuracy_report(clf_bern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 76.95%\n",
      "Accuracy on training data: 1.00\n"
     ]
    }
   ],
   "source": [
    "# TODO - run Logistic Regression for comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "print \"Logistic Regression\"\n",
    "clf_lr = LogisticRegression().fit(xtrain, ytrain)\n",
    "accuracy_report(clf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The year's most inventive comedy.\" is judged by clasifier to be...\n",
      "... a fresh review.\n",
      "\"The year's most inventive comedy.\" is judged by clasifier to be...\n",
      "... a fresh review.\n",
      "\"The year's most inventive comedy.\" is judged by clasifier to be...\n",
      "... a fresh review.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnalyzeReview(\"The year's most inventive comedy.\", clf_mn)\n",
    "AnalyzeReview(\"The year's most inventive comedy.\", clf_bern)\n",
    "AnalyzeReview(\"The year's most inventive comedy.\", clf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
